{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL Framework for HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Self, Optional, Iterable\n",
    "from abc import ABC, abstractclassmethod\n",
    "from collections import deque, namedtuple\n",
    "from dataclasses import field\n",
    "from dataclasses import dataclass, make_dataclass\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.utils import Bunch\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.distributions import Distribution, Normal\n",
    "from torch.optim import Optimizer, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     target  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "..      ...  \n",
       "145       2  \n",
       "146       2  \n",
       "147       2  \n",
       "148       2  \n",
       "149       2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris(as_frame=True)\n",
    "iris_df = iris.frame\n",
    "X = iris.data.to_numpy()\n",
    "y = iris.target.to_numpy()\n",
    "\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_test_split(\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        valid_size: float = 0.2,\n",
    "        test_size: float = 0.2,\n",
    "        random_state: Optional[int] = None,\n",
    "        shuffle: bool = True\n",
    "    ) -> dict:\n",
    "    \n",
    "    # Calculate size of training dataset\n",
    "    valid_test_size = valid_size + test_size\n",
    "    train_size = 1 - valid_test_size\n",
    "    assert train_size > 0 and train_size <= 1,\\\n",
    "        \"size of training dataset must be >0 and <=1\"\n",
    "        \n",
    "    # There is only the training dataset\n",
    "    if valid_test_size == 0:\n",
    "        X_valid = None\n",
    "        y_valid = None\n",
    "        X_test = None\n",
    "        y_test = None\n",
    "    \n",
    "    else:\n",
    "        # Split the training dataset and the remaining dataset\n",
    "        X_train, X_valid_test, y_train, y_valid_test = train_test_split(\n",
    "            X, y,\n",
    "            train_size=train_size,\n",
    "            random_state=random_state,\n",
    "            shuffle=shuffle\n",
    "        )\n",
    "        \n",
    "        assert valid_size >= 0 and valid_size <= 1,\\\n",
    "            \"size of validation dataset must be >=0 and <=1\"\n",
    "            \n",
    "        if valid_size > 0:\n",
    "            # There is no test dataset\n",
    "            if test_size == 0:\n",
    "                X_valid = X_valid_test\n",
    "                y_valid = y_valid_test\n",
    "                X_test = None\n",
    "                y_test = None\n",
    "                \n",
    "            # Split the validation dataset and test dataset\n",
    "            else:\n",
    "                X_valid, X_test, y_valid, y_test = train_test_split(\n",
    "                    X_valid_test, y_valid_test,\n",
    "                    train_size=valid_size / valid_test_size,\n",
    "                    random_state=random_state,\n",
    "                    shuffle=shuffle\n",
    "                )\n",
    "            \n",
    "        # There is no validation dataset\n",
    "        else:\n",
    "            X_valid = None\n",
    "            y_valid = None\n",
    "            X_test = X_valid_test\n",
    "            y_test = y_valid_test\n",
    "    \n",
    "    return {\n",
    "        \"train\": (X_train, y_train),\n",
    "        \"valid\": (X_valid, y_valid),\n",
    "        \"test\": (X_test, y_test)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@dataclass\n",
    "class Bounds:\n",
    "    min: float | int\n",
    "    max: float | int\n",
    "    \n",
    "bounds = Bounds(min=0.1, max=1)\n",
    "type(bounds.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class HpConfig(ABC):\n",
    "\n",
    "    @classmethod\n",
    "    def param_names(cls) -> tuple[str]:\n",
    "        \"\"\"Hyperparameter names.\n",
    "        \"\"\"\n",
    "        \n",
    "        return tuple(cls.__dataclass_fields__.keys())\n",
    "    \n",
    "    @classmethod\n",
    "    def param_type(cls, name: str) -> type:\n",
    "        \"\"\"Data type of the hyperparameter.\n",
    "        \"\"\"\n",
    "        \n",
    "        return cls.__dataclass_fields__.get(name).type\n",
    "    \n",
    "    @classmethod\n",
    "    def dim(cls) -> int:\n",
    "        \"\"\"Dimension of the hyperparameter space, i.e.,\n",
    "        the number of hyperparameters.\n",
    "        \"\"\"\n",
    "        \n",
    "        return len(cls.param_names())\n",
    "    \n",
    "    @classmethod\n",
    "    def from_action(\n",
    "            cls, \n",
    "            action: Iterable[float],\n",
    "            bounds: dict[str, tuple]\n",
    "        ) -> Self:\n",
    "        \n",
    "        hps = {}\n",
    "        for i, hp in enumerate(action):\n",
    "            hp_name = cls.param_names()[i]\n",
    "            hp_type = cls.param_type(hp_name)\n",
    "            hp_min, hp_max = bounds[hp_name]         \n",
    "            hp = hp_type(hp * (hp_max - hp_min) + hp_min)\n",
    "            hps[hp_name] = hp\n",
    "            \n",
    "        return cls(**hps)        \n",
    "    \n",
    "    def to_dict(self) -> dict:\n",
    "        \n",
    "        return self.__dict__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp(cls):\n",
    "    \n",
    "    cls = make_dataclass(\n",
    "        cls.__name__,\n",
    "        cls.__annotations__.items(),\n",
    "        bases=(HpConfig, object)\n",
    "    )    \n",
    "    \n",
    "    return cls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# @dataclass\n",
    "# class SVCConfig(HpConfig):\n",
    "    \n",
    "#     C: float\n",
    "#     gamma: float\n",
    "#     tol: float\n",
    "\n",
    "# @make_hp_config\n",
    "# @dataclass\n",
    "@hp\n",
    "class SVCConfig:\n",
    "    \n",
    "    C: float\n",
    "    gamma: float\n",
    "    tol: float\n",
    "\n",
    "SVCConfig(C=0.1, gamma=0.1, tol=0.01).dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = make_dataclass(\n",
    "    \"A\", \n",
    "    fields=(\n",
    "        (\"C\", float),\n",
    "        (\"tol\", float, field()),\n",
    "    ),\n",
    "    bases=(HpConfig, object)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env:\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            dataset: Bunch,\n",
    "            *,\n",
    "            valid_size: float = 0.2,\n",
    "            test_size: float = 0.2,\n",
    "            state_dim: int = 10,\n",
    "            random_state: Optional[int] = None,\n",
    "        ) -> None:\n",
    "        \n",
    "        # Data\n",
    "        X = dataset.data\n",
    "        y = dataset.target\n",
    "        \n",
    "        # Random state\n",
    "        self._random_state = random_state\n",
    "        \n",
    "        # Split into training, validation and test datasets\n",
    "        split = train_valid_test_split(\n",
    "            X, y,\n",
    "            valid_size=valid_size,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state\n",
    "        )\n",
    "        self._X_train, self._y_train = split[\"train\"]\n",
    "        self._X_valid, self._y_valid = split[\"valid\"]\n",
    "        self._X_test, self._y_test = split[\"test\"]\n",
    "        \n",
    "        # State dimention\n",
    "        self._state_dim = state_dim\n",
    "        \n",
    "        # A buffer of actions taken\n",
    "        self._actions_taken = deque(maxlen=state_dim)\n",
    "        \n",
    "        # Reset env\n",
    "        self._init_state = self.reset()\n",
    "    \n",
    "    @property\n",
    "    def state_dim(self) -> int:\n",
    "        \"\"\"State dimension.\n",
    "        \"\"\"\n",
    "        \n",
    "        return self._state_dim\n",
    "    \n",
    "    @property\n",
    "    def init_state(self) -> np.ndarray:\n",
    "        \"\"\"Initial state.\n",
    "        \"\"\"\n",
    "        \n",
    "        return self._init_state\n",
    "    \n",
    "    def reset(self) -> np.ndarray:\n",
    "        \n",
    "        # Sigmoid function\n",
    "        sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
    "        \n",
    "        # NumPy's random generator\n",
    "        rng = np.random.RandomState(seed=self._random_state)\n",
    "        \n",
    "        # Generate random actions\n",
    "        random_actions = [\n",
    "            sigmoid(rng.randn(SVCConfig.dim())) \n",
    "            for _ in range(self._state_dim)\n",
    "        ]\n",
    "        \n",
    "        # Reset actions taken\n",
    "        self._actions_taken.clear()\n",
    "        self._actions_taken.extend(random_actions)\n",
    "        \n",
    "        # Create an initial state\n",
    "        init_state = np.array(self._actions_taken)\n",
    "        self._init_state = init_state\n",
    "        \n",
    "        return init_state\n",
    "        \n",
    "    \n",
    "    def step(self, action: Iterable[float]) -> tuple[np.ndarray, float]:\n",
    "        \n",
    "        # Generate the next state\n",
    "        self._actions_taken.append(action)\n",
    "        state = np.array(self._actions_taken)\n",
    "        \n",
    "        # Create the HP configuation from the action taken\n",
    "        hp_config = SVCConfig.from_action(\n",
    "            action,\n",
    "            bounds={\n",
    "                \"C\": (0.1, 1.0),\n",
    "                \"gamma\": (0.001, 0.1),\n",
    "                \"tol\": (0.001, 0.1)\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Create the model with selected HP config\n",
    "        svc = SVC(**hp_config.to_dict())\n",
    "        \n",
    "        # Train the model\n",
    "        svc.fit(self._X_train, self._y_train)\n",
    "        \n",
    "        # Compute the accuracy on validation dataset\n",
    "        y_pred = svc.predict(self._X_valid)\n",
    "        reward = accuracy_score(self._y_valid, y_pred)\n",
    "        \n",
    "        return state, reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_hp_config.<locals>._cls(C=0.1, gamma=0.1, tol=0.01)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_config = SVCConfig(\n",
    "    C=0.1,\n",
    "    gamma=0.1,\n",
    "    tol=0.01\n",
    ")\n",
    "\n",
    "hp_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVCConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hp_config(cls):\n",
    "    \n",
    "    class _cls(cls, HpConfig):\n",
    "        pass\n",
    "    \n",
    "    return dataclass(_cls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(hp_config, HpConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Env(\n",
    "    iris, \n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "            self,\n",
    "            action_dim: int\n",
    "        ) -> None:\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self._action_dim = action_dim\n",
    "        self._action = None\n",
    "        self._distribution = None\n",
    "        \n",
    "        self._n_dist_params = 2\n",
    "        \n",
    "        self.fc = nn.Linear(action_dim, 64)\n",
    "        \n",
    "        self.lstm_cell = nn.LSTMCell(\n",
    "            input_size=64,\n",
    "            hidden_size=128\n",
    "        )\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=64,\n",
    "            hidden_size=128,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.dist_param1 = nn.Sequential(\n",
    "            nn.Linear(128, action_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.dist_param2 = nn.Sequential(\n",
    "            nn.Linear(128, action_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    @property\n",
    "    def distribution(self) -> Distribution:\n",
    "        \"\"\"Distribution to generate the action.\n",
    "        \"\"\"\n",
    "        \n",
    "        return self._distribution\n",
    "    \n",
    "    @property\n",
    "    def action(self) -> Tensor:\n",
    "        \"\"\"Action taken.\n",
    "        \"\"\"\n",
    "        \n",
    "        return self._action\n",
    "        \n",
    "    def forward(self, state: Tensor) -> Distribution:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        state : Tensor\n",
    "            (state_dim, action_dim)\n",
    "            (N, state_dim, action_dim)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Distribution\n",
    "            _description_\n",
    "        \"\"\"\n",
    "        \n",
    "        x = self.fc(state)\n",
    "        x, (h, c) = self.lstm(x)\n",
    "        x = x[..., -1, :]\n",
    "        \n",
    "        # Extract parameters for the distribution\n",
    "        mean = self.dist_param1(x)\n",
    "        std = self.dist_param2(x)\n",
    "\n",
    "        # Generate the distributino\n",
    "        distribution = Normal(mean, std)\n",
    "        \n",
    "        # Store the distribution\n",
    "        self._distribution = distribution \n",
    "    \n",
    "        return distribution\n",
    "    \n",
    "    def select_action(self, state: Optional[Tensor]) -> Tensor:\n",
    "        \n",
    "        # Genereate a new distribution\n",
    "        # if the state is provided\n",
    "        if state is not None:\n",
    "            self.forward(state)\n",
    "        \n",
    "        # Select an action randomly from the distribution\n",
    "        action = self._distribution.sample()\n",
    "        \n",
    "        # Clip the action by upper and lower bounds\n",
    "        # More specifically, each entry of the vector must in between 0 and 1\n",
    "        action = action.clip(0, 1)\n",
    "        \n",
    "        # Store the selected action\n",
    "        self._action = action\n",
    "        \n",
    "        return action\n",
    "    \n",
    "    def log_prob(\n",
    "            self, \n",
    "            action: Optional[Tensor] = None, \n",
    "            state: Optional[Tensor] = None\n",
    "        ) -> Tensor:\n",
    "        \"\"\"Compute the log-probability of the action taken.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        action : Optional[Tensor], optional\n",
    "            _description_, by default None\n",
    "        state : Optional[Tensor], optional\n",
    "            _description_, by default None\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tensor\n",
    "            _description_\n",
    "        \"\"\"\n",
    "        \n",
    "        if action is None:\n",
    "            assert state is None,\\\n",
    "                \"state must be set None since action is None\"\n",
    "            action = self._action\n",
    "        \n",
    "        if state is not None:\n",
    "            self.forward(state)\n",
    "        \n",
    "        log_prob = self._distribution.log_prob(action).sum(dim=-1)\n",
    "        \n",
    "        return log_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state shape: torch.Size([10, 3])\n",
      "action shape: torch.Size([3])\n",
      "log-probability shape: torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(\n",
    "    action_dim=SVCConfig.dim()\n",
    ")\n",
    "\n",
    "state = torch.rand(10, 3)\n",
    "action = agent.select_action(state)\n",
    "log_prob = agent.log_prob()\n",
    "\n",
    "print(f\"state shape: {state.shape}\")\n",
    "print(f\"action shape: {action.shape}\")\n",
    "print(f\"log-probability shape: {log_prob.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sma(x: np.ndarray, period: int = 5) -> np.ndarray:\n",
    "    \n",
    "    assert len(x) >= period,\\\n",
    "        \"the length of the array must be at least the length of the period\"\n",
    "    \n",
    "    sma = []\n",
    "    for t in range(period - 1, len(x)):\n",
    "        sma.append(x[t-period+1:t].mean(axis=0))\n",
    "\n",
    "    return np.array(sma)\n",
    "\n",
    "def ema(\n",
    "        x: np.ndarray, \n",
    "        period: int = 5,\n",
    "        alpha: float = 0.2\n",
    "    ) -> np.ndarray:\n",
    "    \n",
    "    assert len(x) >= period,\\\n",
    "        \"the length of the array must be at least the length of the period\"\n",
    "    \n",
    "    ema = []\n",
    "    ema.append(x[:period].mean(axis=0))\n",
    "    for i, t in enumerate(range(period, len(x))):\n",
    "        ema.append(\n",
    "            x[t] * alpha + ema[i] * (1 - alpha)\n",
    "        )\n",
    "\n",
    "    return np.array(ema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ema(np.arange(10), period=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple(\n",
    "    \"Transition\",\n",
    "    (\n",
    "        \"state\",\n",
    "        \"action\",\n",
    "        \"reward\",\n",
    "        \"advantage\",\n",
    "        \"log_prob\"\n",
    "    )\n",
    ")\n",
    "\n",
    "def convert_to_transition_with_fields_as_lists(transitions: list[Transition]) -> Transition:\n",
    "    \n",
    "    return Transition(*map(list, zip(*transitions)))\n",
    "    \n",
    "def convert_to_transitions(transition_with_fields_as_list: Transition) -> Transition:\n",
    "    \n",
    "    return list(map(\n",
    "        lambda fields: Transition(*fields), \n",
    "        zip(*transition_with_fields_as_list)\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one_episode(\n",
    "        env: Env,\n",
    "        agent: Agent,\n",
    "        max_n_timesteps_per_episode: int,\n",
    "        warm_start_duration: int\n",
    "    ) -> list[Transition]:\n",
    "    \n",
    "    states = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    log_probs = []\n",
    "\n",
    "    state = env.reset()\n",
    "    is_done = False\n",
    "    \n",
    "    for t in range(max_n_timesteps_per_episode):\n",
    "        \n",
    "        # Select an action\n",
    "        state = torch.tensor(state, dtype=torch.float)\n",
    "        action = agent.select_action(state)\n",
    "        action = action.detach().numpy()\n",
    "        \n",
    "        # Compute the log-probability of the action taken\n",
    "        log_prob = agent.log_prob()\n",
    "        log_prob = log_prob.detach().item()\n",
    "        \n",
    "        # Interact with the env\n",
    "        next_state, reward = env.step(action)\n",
    "        \n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        rewards.append(reward)\n",
    "        log_probs.append(log_prob)\n",
    "        \n",
    "        # Step to the next state\n",
    "        state = next_state\n",
    "        \n",
    "    # Compute baselines using moving average technique\n",
    "    baselines = ema(np.array(rewards), period=warm_start_duration + 1)\n",
    "        \n",
    "    # Drop the data in the warm start\n",
    "    states = states[warm_start_duration:]\n",
    "    actions = actions[warm_start_duration:]\n",
    "    rewards = rewards[warm_start_duration:]\n",
    "    log_probs = log_probs[warm_start_duration:]\n",
    "    \n",
    "    # Compute advantages\n",
    "    advantages = rewards - baselines\n",
    "    \n",
    "    transition_with_fields_as_list = Transition(\n",
    "        state=states,\n",
    "        action=actions,\n",
    "        reward=rewards,\n",
    "        advantage=advantages,\n",
    "        log_prob=log_probs\n",
    "    )\n",
    "    \n",
    "    # Convert to list of transitions\n",
    "    transitions = convert_to_transitions(transition_with_fields_as_list)\n",
    "    \n",
    "    return transitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer(deque, Dataset):\n",
    "    \n",
    "    def __init__(\n",
    "            self,\n",
    "            env: Env,\n",
    "            capacity: int,\n",
    "            max_n_timesteps_per_episode: int,\n",
    "            warm_start_duration: int\n",
    "        ) -> None:\n",
    "        \n",
    "        super().__init__(maxlen=capacity)\n",
    "\n",
    "        self._env = env\n",
    "        self._capacity = capacity\n",
    "        self._max_n_timesteps_per_episode = max_n_timesteps_per_episode\n",
    "        self._warm_start_duration = warm_start_duration\n",
    "    \n",
    "    @property\n",
    "    def capacity(self) -> int:\n",
    "        return self._capacity\n",
    "    \n",
    "    @property\n",
    "    def max_n_timesteps_per_episode(self) -> int:\n",
    "        return self._max_n_timesteps_per_episode\n",
    "        \n",
    "    def collect(self, agent: Agent) -> None:\n",
    "        \n",
    "        while len(self) < self._capacity:\n",
    "            \n",
    "            # Collect transitions by interacting with the env\n",
    "            transitions = play_one_episode(\n",
    "                env=self._env,\n",
    "                agent=agent,\n",
    "                max_n_timesteps_per_episode=self._max_n_timesteps_per_episode,\n",
    "                warm_start_duration=self._warm_start_duration\n",
    "            )\n",
    "            \n",
    "            # Add to the buffer\n",
    "            self.extend(transitions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppo_loss(\n",
    "        *,\n",
    "        curr_log_prob: Tensor,\n",
    "        old_log_prob: Tensor,\n",
    "        advantage: Tensor,\n",
    "        epsilon: float = 0.2\n",
    "    ) -> Tensor:\n",
    "    \n",
    "    ratio = torch.exp(curr_log_prob - old_log_prob)\n",
    "    \n",
    "    surr1 = ratio * advantage\n",
    "    surr2 = torch.clip(\n",
    "        ratio,\n",
    "        1 - epsilon,\n",
    "        1 + epsilon\n",
    "    ) * advantage\n",
    "    \n",
    "    loss = -torch.min(surr1, surr2).mean()\n",
    "    \n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_agent(\n",
    "        agent: Agent,\n",
    "        optimizer: Optimizer,\n",
    "        replay_buffer_loader: DataLoader,\n",
    "        n_epochs: int,\n",
    "        epsilon: float = 0.2\n",
    "    ):\n",
    "    \n",
    "    for _ in range(n_epochs):\n",
    "        transition: Transition\n",
    "        for transition in replay_buffer_loader:\n",
    "            \n",
    "            # Compute PPO loss\n",
    "            loss = ppo_loss(\n",
    "                curr_log_prob=agent.log_prob(\n",
    "                    transition.action,\n",
    "                    transition.state\n",
    "                ),\n",
    "                old_log_prob=transition.log_prob,\n",
    "                advantage=transition.advantage,\n",
    "                epsilon=epsilon\n",
    "            )\n",
    "            \n",
    "            # Update the agent\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(\n",
    "        agent: Agent,\n",
    "        optimizer: Optimizer,\n",
    "        n_epochs: int,\n",
    "        replay_buffer: ReplayBuffer,\n",
    "        batch_size: int,\n",
    "        n_epochs_for_updating_agent: int,\n",
    "        epsilon: float\n",
    "    ):\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        logging.info(f\"PPO epoch: {epoch + 1}\")\n",
    "        avg_episode_rewards = []\n",
    "        \n",
    "        # Collect transitions\n",
    "        replay_buffer.collect(agent)\n",
    "        \n",
    "        rewards = []\n",
    "        for transition in replay_buffer:\n",
    "            rewards.append(transition.reward)\n",
    "        avg_episode_reward = np.mean(rewards)\n",
    "        avg_episode_rewards.append(avg_episode_reward)\n",
    "        logging.info(f\"average episode rewards: {avg_episode_reward}\")\n",
    "        \n",
    "        # Create a data loader\n",
    "        replay_buffer_loader = DataLoader(\n",
    "            replay_buffer,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "        \n",
    "        # Train the actor and critic   \n",
    "        update_agent(\n",
    "            agent=agent,\n",
    "            optimizer=optimizer,\n",
    "            replay_buffer_loader=replay_buffer_loader,\n",
    "            n_epochs=n_epochs_for_updating_agent,\n",
    "            epsilon=epsilon\n",
    "        )\n",
    "        \n",
    "        # Clear replay buffer\n",
    "        replay_buffer.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    action_dim=SVCConfig.dim()\n",
    ")\n",
    "\n",
    "optimizer = Adam(\n",
    "    agent.parameters(), \n",
    "    lr=0.001\n",
    ")\n",
    "\n",
    "replay_buffer = ReplayBuffer(\n",
    "    env,\n",
    "    capacity=500,\n",
    "    max_n_timesteps_per_episode=20,\n",
    "    warm_start_duration=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-25 16:16:18,301 | INFO | PPO epoch: 1\n",
      "2023-09-25 16:16:19,716 | INFO | average episode rewards: 0.8919333333333334\n",
      "2023-09-25 16:16:20,691 | INFO | PPO epoch: 2\n",
      "2023-09-25 16:16:21,951 | INFO | average episode rewards: 0.9696\n",
      "2023-09-25 16:16:22,887 | INFO | PPO epoch: 3\n",
      "2023-09-25 16:16:24,097 | INFO | average episode rewards: 0.9902000000000001\n",
      "2023-09-25 16:16:25,043 | INFO | PPO epoch: 4\n",
      "2023-09-25 16:16:26,252 | INFO | average episode rewards: 0.9947999999999999\n",
      "2023-09-25 16:16:27,208 | INFO | PPO epoch: 5\n",
      "2023-09-25 16:16:28,409 | INFO | average episode rewards: 0.9954666666666667\n",
      "2023-09-25 16:16:29,346 | INFO | PPO epoch: 6\n",
      "2023-09-25 16:16:30,544 | INFO | average episode rewards: 0.9990666666666668\n",
      "2023-09-25 16:16:31,485 | INFO | PPO epoch: 7\n",
      "2023-09-25 16:16:32,675 | INFO | average episode rewards: 0.9984666666666667\n",
      "2023-09-25 16:16:33,620 | INFO | PPO epoch: 8\n",
      "2023-09-25 16:16:34,807 | INFO | average episode rewards: 1.0\n",
      "2023-09-25 16:16:35,746 | INFO | PPO epoch: 9\n",
      "2023-09-25 16:16:36,957 | INFO | average episode rewards: 0.9999333333333333\n",
      "2023-09-25 16:16:37,909 | INFO | PPO epoch: 10\n",
      "2023-09-25 16:16:39,099 | INFO | average episode rewards: 1.0\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    agent=agent,\n",
    "    optimizer=optimizer,\n",
    "    n_epochs=10,\n",
    "    replay_buffer=replay_buffer,\n",
    "    batch_size=8,\n",
    "    n_epochs_for_updating_agent=5,\n",
    "    epsilon=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normal(loc: torch.Size([4, 3]), scale: torch.Size([4, 3]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.distribution.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7295, 0.6731, 0.3120])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normal(loc: torch.Size([4, 3]), scale: torch.Size([4, 3]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVCConfig(C=0.7565273582935333, gamma=0.06763471615314484, tol=0.03189250004291534)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_config = SVCConfig.from_action(\n",
    "    action=agent.action.detach().numpy(),\n",
    "    bounds={\n",
    "        \"C\": (0.1, 1.0),\n",
    "        \"gamma\": (0.001, 0.1),\n",
    "        \"tol\": (0.001, 0.1)\n",
    "    }\n",
    ")\n",
    "\n",
    "hp_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(**hp_config.to_dict())\n",
    "\n",
    "svc.fit(\n",
    "    env._X_train,\n",
    "    env._y_train\n",
    ")\n",
    "\n",
    "accuracy_score(\n",
    "    env._y_test,\n",
    "    svc.predict(env._X_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC()\n",
    "\n",
    "svc.fit(\n",
    "    env._X_train,\n",
    "    env._y_train\n",
    ")\n",
    "\n",
    "accuracy_score(\n",
    "    env._y_test,\n",
    "    svc.predict(env._X_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linguaml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
